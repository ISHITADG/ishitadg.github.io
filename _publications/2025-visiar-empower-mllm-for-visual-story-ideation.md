---
layout: publication
title: "VISIAR: Empower MLLM for visual story ideation"
authors: "Z Xia, S Sarkhel, M Tanjim, S Petrangeli, I Dasgupta, Y Chen, J Xu, D Liu, ..."
venue: "ACL Findings 2025"
year: 2025
citations: 0
link: "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=okBrMn8AAAAJ&sortby=pubdate&citation_for_view=okBrMn8AAAAJ:WF5omc3nYNoC"
image: "/assets/img/visiar1.png"
date: 2025-08-01
---

## Abstract

Ideation, the process of forming ideas from concepts, is a big part of the content creation process. However, the noble goal of helping visual content creators by suggesting meaningful sequences of visual assets from a limited collection is challenging. It requires a nuanced understanding of visual assets and the integration of open-world knowledge to support creative exploration. Despite its importance, this task has yet to be explored fully in existing literature. To fill this gap, we propose Visual Story Ideation, a novel and underexplored task focused on the automated selection and arrangement of visual assets into coherent sequences that convey expressive storylines. We also present VISIAR, Visual Ideation through Sequence Integration and Asset Rearrangement, a robust framework leveraging Multimodal Large Language Models (MLLMs), and a novel Story Graph mechanism. Our framework operates in three key stages: visual content understanding, candidate asset selection, and asset rearrangement via MLLMs. In addition, we curated a new benchmark dataset, called VTravel, to evaluate our methods both qualitatively and quantitatively. User studies and GPT-as-the-judge evaluation show that our approach surpasses GPT-4o based baseline by an average of 33.5% and 18.5% across three different metrics, demonstrating the effectiveness of our framework for generating compelling visual stories.

## Figures

![VISIAR Framework Overview](/assets/img/visiar1.png)

![User Study Results](/assets/img/visiar2.png)

## Links

- [ACL Anthology](https://aclanthology.org/2025.findings-acl.945/)
- [Google Scholar](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=okBrMn8AAAAJ&sortby=pubdate&citation_for_view=okBrMn8AAAAJ:WF5omc3nYNoC)
